{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data.datasets.random_dataset import RandomDataset\n",
    "from data.datasets.golden_panels import GoldenPanelsDataset\n",
    "\n",
    "from networks.plain_ssupervae import PlainSSuperVAE\n",
    "from networks.ssupervae_contextual_attentional import SSuperVAEContextualAttentional\n",
    "from training.ssupervae_contextual_attn_trainer import SSuperVAEContextualAttentionalTrainer\n",
    "from training.vae_trainer import VAETrainer\n",
    "from utils.config_utils import read_config, Config\n",
    "from utils.plot_utils import *\n",
    "from utils.logging_utils import *\n",
    "from utils import pytorch_util as ptu\n",
    "from utils.image_utils import *\n",
    "from configs.base_config import *\n",
    "from functional.losses.elbo import elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_loss_model(model_name, model, best_loss):\n",
    "    print('[INFO] Current best loss: ' + str(best_loss))\n",
    "    torch.save(model, base_dir + 'playground/ssupervae/weights/' + model_name + \".pth\")\n",
    "\n",
    "\n",
    "def train(data_loader,\n",
    "          config,\n",
    "          panel_dim,\n",
    "          model_name='plain_ssupervae',\n",
    "          cont_epoch=-1,\n",
    "          cont_model=None):\n",
    "    # loading config\n",
    "    print(\"[INFO] Initiate training...\")\n",
    "\n",
    "    # creating model and training details\n",
    "    net = SSuperVAEContextualAttentional(config.backbone,\n",
    "                                         panel_img_size=panel_dim,\n",
    "                                         latent_dim=config.latent_dim,\n",
    "                                         embed_dim=config.embed_dim,\n",
    "                                         seq_size=config.seq_size,\n",
    "                                         decoder_channels=config.decoder_channels,\n",
    "                                         gen_img_size=config.image_dim).to(ptu.device)\n",
    "\n",
    "    criterion = elbo\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(),\n",
    "                           lr=config.lr,\n",
    "                           betas=(config.beta_1, config.beta_2),\n",
    "                           weight_decay=config.weight_decay)\n",
    "\n",
    "    d_params = list(net.local_disc.parameters()) + list(net.global_disc.parameters())\n",
    "    optimizer_disc = optim.Adam(d_params,\n",
    "                                lr=config.lr,\n",
    "                                betas=(config.beta_1, config.beta_2),\n",
    "                                weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer,\n",
    "                                            lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                            last_epoch=-1)\n",
    "\n",
    "    scheduler_disc = optim.lr_scheduler.LambdaLR(optimizer_disc,\n",
    "                                            lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                            last_epoch=-1)\n",
    "    # init trainer\n",
    "    trainer = SSuperVAEContextualAttentionalTrainer(model=net,\n",
    "                                                    config_disc=config,\n",
    "                                                    model_name=model_name,\n",
    "                                                    criterion=criterion,\n",
    "                                                    train_loader=data_loader,\n",
    "                                                    test_loader=None,\n",
    "                                                    epochs=config.train_epochs,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    optimizer_disc=optimizer_disc,\n",
    "                                                    scheduler=scheduler,\n",
    "                                                    scheduler_disc=scheduler_disc,\n",
    "                                                    grad_clip=config.g_clip,\n",
    "                                                    best_loss_action=lambda m, l: save_best_loss_model(model_name, m,\n",
    "                                                                                                       l),\n",
    "                                                    save_dir=base_dir + 'playground/ssupervae/',\n",
    "                                                    checkpoint_every_epoch=True\n",
    "                                                    )\n",
    "\n",
    "    if cont_epoch > -1:\n",
    "        epoch, losses = trainer.load_checkpoint(epoch=cont_epoch)\n",
    "    elif cont_model is not None:\n",
    "        epoch, losses = trainer.load_checkpoint(alternative_chkpt_path=cont_model)\n",
    "        print(\"[INFO] Continues from loaded model in epoch:\", epoch)\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        epoch, losses = None, {}\n",
    "\n",
    "    train_losses, test_losses = trainer.train_epochs(starting_epoch=epoch, losses=losses)\n",
    "\n",
    "    print(\"[INFO] Completed training!\")\n",
    "\n",
    "    save_training_plot(train_losses['loss'],\n",
    "                       test_losses['loss'],\n",
    "                       \"Plain_SSuperVAE Losses\",\n",
    "                       base_dir + 'playground/supervae/' + f'results/ssupervae_plot.png'\n",
    "                       )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptu.set_gpu_mode(True)\n",
    "config = read_config(Config.VAE_CONTEXT_ATTN)\n",
    "golden_age_config = read_config(Config.GOLDEN_AGE)\n",
    "\n",
    "panel_dim = golden_age_config.panel_dim[0]\n",
    "\n",
    "cont_epoch = -1\n",
    "cont_model = None  # \"playground/ssupervae/weights/model-18.pth\"\n",
    "# TODO: move this to config\n",
    "limit_size = -1\n",
    "\n",
    "# data = RandomDataset((3, 3, 360, 360), (3, config.image_dim, config.image_dim))\n",
    "data = GoldenPanelsDataset(golden_age_config.panel_path,\n",
    "                           golden_age_config.sequence_path,\n",
    "                           golden_age_config.panel_dim,\n",
    "                           config.image_dim,\n",
    "                           augment=False,\n",
    "                           mask_val=golden_age_config.mask_val,\n",
    "                           mask_all=golden_age_config.mask_all,\n",
    "                           return_mask=golden_age_config.return_mask,\n",
    "                           train_test_ratio=golden_age_config.train_test_ratio,\n",
    "                           train_mode=True,\n",
    "                           limit_size=limit_size)\n",
    "data_loader = DataLoader(data, batch_size=config.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initiate training...\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18016 [00:00<?, ?it/s]/kuacc/users/gsoykan20/.conda/envs/ulad/lib/python3.6/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Epoch 0, loss 17420.7769, reconstruction_loss 18029.7846, kl_loss 39.2964, l1_fine 1.0234, wgan_g -649.3275, wgan_d -481.1501, wgan_gp 18.5179, d -295.9715: 100%|██████████| 18016/18016 [42:39<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current best loss: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/gsoykan20/.conda/envs/ulad/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch 1, loss 17648.5780, reconstruction_loss 17877.0423, kl_loss 50.4639, l1_fine 1.0324, wgan_g -279.9607, wgan_d -531.4763, wgan_gp 20.4071, d -327.4054: 100%|██████████| 18016/18016 [42:39<00:00,  7.04it/s]\n",
      "Epoch 2, loss 17444.7711, reconstruction_loss 17589.7201, kl_loss 66.2533, l1_fine 0.9996, wgan_g -212.2020, wgan_d -535.4358, wgan_gp 20.4809, d -330.6265: 100%|██████████| 18016/18016 [43:04<00:00,  6.97it/s]\n",
      "Epoch 3, loss 17090.4572, reconstruction_loss 17252.7519, kl_loss 69.4212, l1_fine 0.9778, wgan_g -232.6935, wgan_d -512.8566, wgan_gp 19.6407, d -316.4497: 100%|██████████| 18016/18016 [42:51<00:00,  7.01it/s]\n",
      "Epoch 4, loss 16996.2053, reconstruction_loss 17197.4961, kl_loss 74.1443, l1_fine 0.9797, wgan_g -276.4148, wgan_d -493.3303, wgan_gp 18.8149, d -305.1816: 100%|██████████| 18016/18016 [43:21<00:00,  6.92it/s]\n",
      "Epoch 5, loss 17092.5795, reconstruction_loss 17322.9721, kl_loss 82.8913, l1_fine 0.9929, wgan_g -314.2768, wgan_d -542.6121, wgan_gp 20.5370, d -337.2419: 100%|██████████| 18016/18016 [42:49<00:00,  7.01it/s]\n",
      "Epoch 6, loss 16694.4766, reconstruction_loss 17019.0745, kl_loss 85.0402, l1_fine 0.9800, wgan_g -410.6181, wgan_d -530.4421, wgan_gp 20.1953, d -328.4891:  79%|███████▊  | 14168/18016 [33:37<09:08,  7.02it/s]"
     ]
    }
   ],
   "source": [
    "model = train(data_loader,\n",
    "              config,\n",
    "              model_name=get_dt_string() + \"_model\",\n",
    "              cont_epoch=cont_epoch,\n",
    "              cont_model=cont_model,\n",
    "              panel_dim=panel_dim)\n",
    "torch.save(model, base_dir + 'playground/ssupervae/results/' + \"ssuper_vae_context_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment start time: may 14 - 18.04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
