{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data.datasets.golden_panels import GoldenPanelsDataset\n",
    "from networks.ssupervae_contextual_attentional import SSuperVAEContextualAttentional\n",
    "from training.ssupervae_contextual_attn_trainer import SSuperVAEContextualAttentionalTrainer\n",
    "from utils.config_utils import read_config, Config\n",
    "from utils.plot_utils import *\n",
    "from utils.logging_utils import *\n",
    "from utils.image_utils import *\n",
    "from configs.base_config import *\n",
    "from functional.losses.elbo import elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_loss_model(model_name, model, best_loss):\n",
    "    print('[INFO] Current best loss: ' + str(best_loss))\n",
    "    torch.save(model, base_dir + 'playground/ssupervae_contextual_attention/weights/' + model_name + \".pth\")\n",
    "\n",
    "\n",
    "def train(data_loader,\n",
    "          config,\n",
    "          panel_dim,\n",
    "          model_name='ssupervae_contextual_attention',\n",
    "          cont_epoch=-1,\n",
    "          cont_model=None):\n",
    "    # loading config\n",
    "    print(\"[INFO] Initiate training...\")\n",
    "\n",
    "    # creating model and training details\n",
    "    net = SSuperVAEContextualAttentional(config.backbone,\n",
    "                                         panel_img_size=panel_dim,\n",
    "                                         latent_dim=config.latent_dim,\n",
    "                                         embed_dim=config.embed_dim,\n",
    "                                         seq_size=config.seq_size,\n",
    "                                         decoder_channels=config.decoder_channels,\n",
    "                                         gen_img_size=config.image_dim).to(ptu.device)\n",
    "\n",
    "    criterion = elbo\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(),\n",
    "                           lr=config.lr,\n",
    "                           betas=(config.beta_1, config.beta_2),\n",
    "                           weight_decay=config.weight_decay)\n",
    "\n",
    "    d_params = list(net.local_disc.parameters()) + list(net.global_disc.parameters())\n",
    "    optimizer_disc = optim.Adam(d_params,\n",
    "                                lr=config.lr,\n",
    "                                betas=(config.beta_1, config.beta_2),\n",
    "                                weight_decay=config.weight_decay)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer,\n",
    "                                            lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                            last_epoch=-1)\n",
    "\n",
    "    scheduler_disc = optim.lr_scheduler.LambdaLR(optimizer_disc,\n",
    "                                                 lambda epoch: (config.train_epochs - epoch) / config.train_epochs,\n",
    "                                                 last_epoch=-1)\n",
    "    # init trainer\n",
    "    trainer = SSuperVAEContextualAttentionalTrainer(model=net,\n",
    "                                                    config_disc=config,\n",
    "                                                    model_name=model_name,\n",
    "                                                    criterion=criterion,\n",
    "                                                    train_loader=data_loader,\n",
    "                                                    test_loader=None,\n",
    "                                                    epochs=config.train_epochs,\n",
    "                                                    optimizer=optimizer,\n",
    "                                                    optimizer_disc=optimizer_disc,\n",
    "                                                    scheduler=scheduler,\n",
    "                                                    scheduler_disc=scheduler_disc,\n",
    "                                                    grad_clip=config.g_clip,\n",
    "                                                    best_loss_action=lambda m, l: save_best_loss_model(model_name, m,\n",
    "                                                                                                       l),\n",
    "                                                    save_dir=base_dir + 'playground/ssupervae_contextual_attention/',\n",
    "                                                    checkpoint_every_epoch=True\n",
    "                                                    )\n",
    "\n",
    "    if cont_epoch > -1:\n",
    "        epoch, losses = trainer.load_checkpoint(epoch=cont_epoch)\n",
    "    elif cont_model is not None:\n",
    "        epoch, losses = trainer.load_checkpoint(alternative_chkpt_path=cont_model)\n",
    "        print(\"[INFO] Continues from loaded model in epoch:\", epoch)\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        epoch, losses = None, {}\n",
    "\n",
    "    train_losses, test_losses = trainer.train_epochs(starting_epoch=epoch, losses=losses)\n",
    "\n",
    "    print(\"[INFO] Completed training!\")\n",
    "\n",
    "    save_training_plot(train_losses['loss'],\n",
    "                       test_losses['loss'],\n",
    "                       \"Plain_SSuperVAE Losses\",\n",
    "                       base_dir + 'playground/ssupervae_contextual_attention/' + f'results/ssupervae_plot.png'\n",
    "                       )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptu.set_gpu_mode(True)\n",
    "config = read_config(Config.VAE_CONTEXT_ATTN)\n",
    "golden_age_config = read_config(Config.GOLDEN_AGE)\n",
    "\n",
    "panel_dim = golden_age_config.panel_dim[0]\n",
    "\n",
    "cont_epoch = -1\n",
    "cont_model = None  # \"playground/ssupervae/weights/model-18.pth\"\n",
    "# TODO: move this to config\n",
    "limit_size = -1\n",
    "\n",
    "# data = RandomDataset((3, 3, 360, 360), (3, config.image_dim, config.image_dim))\n",
    "data = GoldenPanelsDataset(golden_age_config.panel_path,\n",
    "                           golden_age_config.sequence_path,\n",
    "                           golden_age_config.panel_dim,\n",
    "                           config.image_dim,\n",
    "                           augment=False,\n",
    "                           mask_val=golden_age_config.mask_val,\n",
    "                           mask_all=golden_age_config.mask_all,\n",
    "                           return_mask=golden_age_config.return_mask,\n",
    "                           return_mask_coordinates=golden_age_config.return_mask_coordinates,\n",
    "                           train_test_ratio=golden_age_config.train_test_ratio,\n",
    "                           train_mode=golden_age_config.train_mode,\n",
    "                           limit_size=limit_size)\n",
    "data_loader = DataLoader(data, batch_size=config.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initiate training...\n",
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18016 [00:00<?, ?it/s]/kuacc/users/gsoykan20/.conda/envs/ulad/lib/python3.6/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Epoch 0, loss 12571.9304, reconstruction_loss 12714.2855, kl_loss 11.3321, l1_fine 0.4600, wgan_g -154.1472, wgan_d -128.3612, wgan_gp 3.9481, d -88.8804: 100%|██████████| 18016/18016 [43:27<00:00,  6.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current best loss: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/users/gsoykan20/.conda/envs/ulad/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Epoch 1, loss 12522.3450, reconstruction_loss 12666.9658, kl_loss 20.8161, l1_fine 0.4586, wgan_g -165.8956, wgan_d -135.1522, wgan_gp 4.1447, d -93.7050: 100%|██████████| 18016/18016 [43:26<00:00,  6.91it/s]\n",
      "Epoch 2, loss 12442.1849, reconstruction_loss 12553.7072, kl_loss 22.6358, l1_fine 0.4392, wgan_g -134.5972, wgan_d -125.9457, wgan_gp 3.7635, d -88.3103: 100%|██████████| 18016/18016 [43:27<00:00,  6.91it/s]\n",
      "Epoch 3, loss 12424.9355, reconstruction_loss 12581.6878, kl_loss 28.0906, l1_fine 0.4426, wgan_g -185.2855, wgan_d -126.8436, wgan_gp 3.8968, d -87.8755: 100%|██████████| 18016/18016 [43:30<00:00,  6.90it/s]\n",
      "Epoch 4, loss 12455.3959, reconstruction_loss 12583.1918, kl_loss 27.0573, l1_fine 0.4406, wgan_g -155.2936, wgan_d -129.8154, wgan_gp 3.9526, d -90.2890: 100%|██████████| 18016/18016 [43:34<00:00,  6.89it/s]\n",
      "Epoch 5, loss 12389.4014, reconstruction_loss 12476.3221, kl_loss 27.9984, l1_fine 0.4239, wgan_g -115.3431, wgan_d -120.2096, wgan_gp 3.6209, d -84.0003:  29%|██▉       | 5208/18016 [12:39<30:58,  6.89it/s]"
     ]
    }
   ],
   "source": [
    "model = train(data_loader,\n",
    "              config,\n",
    "              model_name=get_dt_string() + \"_model\",\n",
    "              cont_epoch=cont_epoch,\n",
    "              cont_model=cont_model,\n",
    "              panel_dim=panel_dim)\n",
    "torch.save(model, base_dir + 'playground/ssupervae_contextual_attention/results/' + \"ssuper_vae_context_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment start time: may 14 - 18.04"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}